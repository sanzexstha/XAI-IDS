{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-core version\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "datasets = [\n",
    "#  Dataset.IRIS2D,\n",
    "  Dataset.WINE,\n",
    "  Dataset.PIMA,\n",
    "  Dataset.BC\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "  Classifier.GNB,\n",
    "  Classifier.MLP,\n",
    "  Classifier.RF\n",
    "]\n",
    "\n",
    "kernel_widths = [\n",
    "  0.1,\n",
    "  # 0.2,\n",
    "  0.3,\n",
    "  # 0.4,\n",
    "  0.5,\n",
    "  # 0.6,\n",
    "  # 0.7,\n",
    "  # 0.8,\n",
    "  # 0.9,\n",
    "  1.0,\n",
    "  # 1.5,\n",
    "  # 2.0,\n",
    "  # 2.5,\n",
    "  # 3.0,\n",
    "  # 3.5,\n",
    "  lambda n: np.sqrt(n) * .75,\n",
    "  4.0\n",
    "]\n",
    "\n",
    "columns = pd.MultiIndex.from_product([datasets, classifiers])\n",
    "\n",
    "def faithfulness(options):\n",
    "  dataset, classifier, kernel_width = options\n",
    "  data = dataset.instance\n",
    "  Xtr = data.data\n",
    "  clf = classifier.instance\n",
    "  clf.fit(Xtr, data.target)\n",
    "\n",
    "  points, points2 = do_experiment(Xtr, clf, kernel_width, plot_sample_data=False)\n",
    "  score_lemon = np.mean(points[:,1])\n",
    "  score_lime = np.mean(points2[:,1])\n",
    "\n",
    "  return score_lime, score_lemon\n",
    "\n",
    "\n",
    "import contextlib\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "from joblib import delayed, Parallel, cpu_count\n",
    "\n",
    "parameters = list(product(datasets, classifiers, kernel_widths))\n",
    "\n",
    "\n",
    "with tqdm_joblib(tqdm(total=len(parameters))) as progress_bar:\n",
    "  result = Parallel(n_jobs=cpu_count())(delayed(faithfulness)(p) for p in parameters)\n",
    "\n",
    "\n",
    "_RemoteTraceback                          Traceback (most recent call last)\n",
    "_RemoteTraceback:\n",
    "\"\"\"\n",
    "Traceback (most recent call last):\n",
    "  File \"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n",
    "    r = call_item()\n",
    "  File \"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n",
    "    return self.fn(*self.args, **self.kwargs)\n",
    "  File \"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n",
    "    return [func(*args, **kwargs)\n",
    "  File \"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n",
    "    return [func(*args, **kwargs)\n",
    "  File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_12720\\403947192.py\", line 47, in faithfulness\n",
    "  File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_12720\\556752134.py\", line 71, in do_experiment\n",
    "  File \"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lime\\lime_tabular.py\", line 452, in explain_instance\n",
    "    ret_exp.score, ret_exp.local_pred) = self.base.explain_instance_with_data(\n",
    "  File \"c:\\Users\\Acer\\XAI_IDS\\IDS\\pwla_lime\\pwla_line_3d.py\", line 94, in explain_instance_with_data\n",
    "    easy_model.fit(\n",
    "  File \"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1130, in fit\n",
    "    return super().fit(X, y, sample_weight=sample_weight)\n",
    "  File \"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 854, in fit\n",
    "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
    "  File \"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 284, in _preprocess_data\n",
    "    X_offset = np.average(X, axis=0, weights=sample_weight)\n",
    "  File \"<__array_function__ internals>\", line 180, in average\n",
    "  File \"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 547, in average\n",
    "    raise ZeroDivisionError(\n",
    "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
